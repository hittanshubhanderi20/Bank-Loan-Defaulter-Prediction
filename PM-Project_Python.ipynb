{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Installing Libraries to run Bayesian Model in python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb9_k-Dks8Ch",
        "outputId": "69327962-1f9c-4906-b355-45243fa4d27d"
      },
      "outputs": [],
      "source": [
        "#pip install --upgrade pip\n",
        "#pip install pgmpy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Default Bayesian Model Python Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/hittanshubhanderi/Downloads/train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[1;32m      8\u001b[0m \u001b[39m# Load the dataset into a pandas DataFrame\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/Users/hittanshubhanderi/Downloads/train.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m \u001b[39m# Select the relevant columns\u001b[39;00m\n\u001b[1;32m     12\u001b[0m cols \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mLoan Amount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFunded Amount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFunded Amount Investor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTerm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mBatch Enrolled\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mInterest Rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEmployment Duration\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mHome Ownership\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mVerification Status\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLoan Title\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mDebt to Income\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDelinquency - two years\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mInquiries - six months\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mOpen Account\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mLast Week Pay\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAccounts Now Delinquent\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTotal Collection Amount\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mTotal Current Balance\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTotal Revolving Credit Limit\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLoan Status\u001b[39m\u001b[39m'\u001b[39m]\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/hittanshubhanderi/Downloads/train.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
        "from pgmpy.estimators import HillClimbSearch, BicScore\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "data = pd.read_csv('/Users/hittanshubhanderi/Downloads/train.csv')\n",
        "\n",
        "# Select the relevant columns\n",
        "cols = ['Loan Amount', 'Funded Amount', 'Funded Amount Investor', 'Term', 'Batch Enrolled',\n",
        "        'Interest Rate', 'Employment Duration', 'Home Ownership', 'Verification Status', 'Loan Title',\n",
        "        'Debt to Income', 'Delinquency - two years', 'Inquiries - six months', 'Open Account',\n",
        "        'Public Record', 'Revolving Balance', 'Revolving Utilization', 'Total Accounts',\n",
        "        'Initial List Status', 'Total Received Interest', 'Total Received Late Fee', 'Recoveries',\n",
        "        'Collection Recovery Fee', 'Collections 12 Months Excl Med', 'Application Type',\n",
        "        'Last Week Pay', 'Accounts Now Delinquent', 'Total Collection Amount',\n",
        "        'Total Current Balance', 'Total Revolving Credit Limit', 'Loan Status']\n",
        "data = data[cols]\n",
        "\n",
        "# Preprocess the dataset by converting categorical variables into numerical values using one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Term', 'Batch Enrolled', 'Home Ownership', 'Verification Status',\n",
        "                                     'Loan Title', 'Initial List Status', 'Application Type', 'Loan Status'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data = data.sample(frac=0.8, random_state=1)\n",
        "test_data = data.drop(train_data.index)\n",
        "\n",
        "# Define the structure of the Bayesian Network using the BayesianModel class from pgmpy\n",
        "model = BayesianModel([('Loan Amount', 'Loan Status'),\n",
        "                       ('Funded Amount', 'Loan Status'),\n",
        "                       ('Funded Amount Investor', 'Loan Status'),\n",
        "                       ('Term_ 36 months', 'Loan Status'),\n",
        "                       ('Batch Enrolled_', 'Loan Status'),\n",
        "                       ('Interest Rate', 'Loan Status'),\n",
        "                       ('Employment Duration', 'Loan Status'),\n",
        "                       ('Home Ownership_MORTGAGE', 'Loan Status'),\n",
        "                       ('Home Ownership_NONE', 'Loan Status'),\n",
        "                       ('Home Ownership_OTHER', 'Loan Status'),\n",
        "                       ('Home Ownership_OWN', 'Loan Status'),\n",
        "                       ('Home Ownership_RENT', 'Loan Status'),\n",
        "                       ('Verification Status_Not Verified', 'Loan Status'),\n",
        "                       ('Verification Status_Source Verified', 'Loan Status'),\n",
        "                       ('Verification Status_Verified', 'Loan Status'),\n",
        "                       ('Loan Title_Business Loan', 'Loan Status'),\n",
        "                       ('Loan Title_Car financing', 'Loan Status'),\n",
        "                       ('Loan Title_Credit card refinancing', 'Loan Status'),\n",
        "                       ('Loan Title_Debt consolidation', 'Loan Status'),\n",
        "                       ('Loan Title_Green loan', 'Loan Status'),\n",
        "                       ('Loan Title_Home buying', 'Loan Status'),\n",
        "                       ('Loan Title_Home improvement', 'Loan Status'),\n",
        "                       ('Loan Title_Major purchase', 'Loan Status'),\n",
        "                       ('Loan Title_Medical expenses', 'Loan Status'),\n",
        "                       ('Loan Title_Moving and relocation', 'Loan Status'),\n",
        "                       ('Loan Title_Other', 'Loan Status'),\n",
        "                       ('Loan Title_Vacation', 'Loan Status'),\n",
        "                       ('Loan Title_Wedding Loan', 'Loan Status'),\n",
        "                       ('Debt to Income', 'Loan Status'),\n",
        "                       ('Delinquency - two years', 'Loan Status'),\n",
        "                       ('Inquiries - six months', 'Loan Status'),\n",
        "                       ('Open Account', 'Loan Status'),\n",
        "                       ('Public Record', 'Loan Status'),\n",
        "                       ('Revolving Balance', 'Loan Status'),\n",
        "                       ('Revolving Utilization', 'Loan Status'),\n",
        "                       ('Total Accounts', 'Loan Status'),\n",
        "                       ('Initial List Status_f', 'Loan Status'),\n",
        "                       ('Initial List Status_w', 'Loan Status'),\n",
        "                       ('Total Received Interest', 'Loan Status'),\n",
        "                       ('Total Received Late Fee', 'Loan Status'),\n",
        "                       ('Recoveries', 'Loan Status'),\n",
        "                       ('Collection Recovery Fee', 'Loan Status'),\n",
        "                       ('Collections 12 Months Excl Med', 'Loan Status'),\n",
        "                       ('Application Type_INDIVIDUAL', 'Loan Status'),\n",
        "                       ('Application Type_JOINT', 'Loan Status'),\n",
        "                       ('Last Week Pay', 'Loan Status'),\n",
        "                       ('Accounts Now Delinquent', 'Loan Status'),\n",
        "                       ('Total Collection Amount', 'Loan Status'),\n",
        "                       ('Total Current Balance', 'Loan Status'),\n",
        "                       ('Total Revolving Credit Limit', 'Loan Status')])\n",
        "\n",
        "# Use Tan's algorithm to learn the structure of the Bayesian Network from the training data\n",
        "estimator = BayesianEstimator(model, train_data)\n",
        "model.fit(train_data, estimator=estimator, prior_type='BDeu')\n",
        "\n",
        "# Evaluate the performance of the Bayesian Network on the testing data\n",
        "preds = model.predict(test_data.drop('Loan Status', axis=1))\n",
        "accuracy = accuracy_score(test_data['Loan Status'], preds)\n",
        "precision = precision_score(test_data['Loan Status'], preds)\n",
        "recall = recall_score(test_data['Loan Status'], preds)\n",
        "f1 = f1_score(test_data['Loan Status'], preds)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-score:', f1)\n",
        "\n",
        "# Use the Markov algorithm to learn the structure of the Bayesian Network from the training data\n",
        "estimator = MaximumLikelihoodEstimator(model, train_data)\n",
        "model.fit(train_data, estimator=estimator)\n",
        "\n",
        "# Evaluate the performance of the Bayesian Network on the testing data\n",
        "preds = model.predict(test_data.drop('Loan Status', axis=1))\n",
        "accuracy = accuracy_score(test_data['Loan Status'], preds)\n",
        "precision = precision_score(test_data['Loan Status'], preds)\n",
        "recall = recall_score(test_data['Loan Status'], preds)\n",
        "f1 = f1_score(test_data['Loan Status'], preds)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-score:', f1)\n",
        "\n",
        "# Use the Markov algorithm with feature selection to learn the structure of the Bayesian Network from the training data\n",
        "hc = HillClimbSearch(train_data, scoring_method=BicScore(train_data))\n",
        "best_model = hc.estimate()\n",
        "estimator = MaximumLikelihoodEstimator(best_model, train_data)\n",
        "best_model.fit(train_data, estimator=estimator)\n",
        "\n",
        "# Evaluate the performance of the Bayesian Network on the testing data\n",
        "preds = best_model.predict(test_data.drop('Loan Status', axis=1))\n",
        "accuracy = accuracy_score(test_data['Loan Status'], preds)\n",
        "precision = precision_score(test_data['Loan Status'], preds)\n",
        "recall = recall_score(test_data['Loan Status'], preds)\n",
        "f1 = f1_score(test_data['Loan Status'], preds)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-score:', f1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bayesian Model Python Code with Discretizetion the continuous variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
        "from pgmpy.estimators import HillClimbSearch, BDeuScore, K2Score\n",
        "from pgmpy.estimators import PC\n",
        "from pgmpy.inference import VariableElimination\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/Users/hittanshubhanderi/Downloads/trtr.csv')\n",
        "\n",
        "# Select relevant columns for analysis\n",
        "columns = ['Loan Amount', 'Term', 'Interest Rate', 'Employment Duration', 'Home Ownership', 'Verification Status', 'Loan Title', 'Debit to Income', 'Delinquency - two years', 'Inquires - six months', 'Open Account', 'Revolving Balance', 'Total Accounts', 'Loan Status']\n",
        "data = data[columns]\n",
        "\n",
        "# Discretize the continuous variables\n",
        "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
        "discretized_cols = discretizer.fit_transform(data[['Loan Amount', 'Interest Rate', 'Debit to Income', 'Delinquency - two years', 'Inquires - six months', 'Open Account', 'Revolving Balance', 'Total Accounts']])\n",
        "data[['Loan Amount', 'Interest Rate', 'Debit to Income', 'Delinquency - two years', 'Inquires - six months', 'Open Account', 'Revolving Balance', 'Total Accounts']] = discretized_cols.astype('int64')\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train_data = data.sample(frac=0.7, random_state=1)\n",
        "test_data = data.drop(train_data.index)\n",
        "\n",
        "# Define the structure of the Bayesian Network using the Tan algorithm\n",
        "model_tan = BayesianModel([('Loan Amount', 'Loan Status'), ('Term', 'Loan Status'), ('Interest Rate', 'Loan Status'), ('Employment Duration', 'Loan Status'),\n",
        "                           ('Home Ownership', 'Loan Status'), ('Verification Status', 'Loan Status'), ('Loan Title', 'Loan Status'), ('Debit to Income', 'Loan Status'),\n",
        "                           ('Delinquency - two years', 'Loan Status'), ('Inquires - six months', 'Loan Status'), ('Open Account', 'Loan Status'), ('Revolving Balance', 'Loan Status'),\n",
        "                           ('Total Accounts', 'Loan Status')])\n",
        "\n",
        "# Estimate the parameters of the Bayesian Network using the Maximum Likelihood Estimator\n",
        "estimator_tan = MaximumLikelihoodEstimator(model_tan, train_data)\n",
        "model_tan.fit(train_data)\n",
        "\n",
        "# Define the structure of the Bayesian Network using the Markov algorithm\n",
        "hc = HillClimbSearch(train_data, scoring_method=BDeuScore(train_data))\n",
        "best_model = hc.estimate()\n",
        "model_markov = BayesianModel(best_model.edges())\n",
        "\n",
        "# Estimate the parameters of the Bayesian Network using the Bayesian Estimator\n",
        "estimator_markov = BayesianEstimator(model_markov, train_data)\n",
        "model_markov.fit(train_data, estimator_markov)\n",
        "\n",
        "# Define the structure of the Bayesian Network using the Markov with feature selection algorithm\n",
        "est = PC(train_data)\n",
        "skeleton = est.estimate_skeleton()\n",
        "model_markov_fs = est.skeleton_to_bn(skeleton)\n",
        "model_markov_fs.fit(train_data, estimator=BayesianEstimator)\n",
        "\n",
        "# Predict the loan status for the test data using the Variable Elimination method for the Tan algorithm\n",
        "inference_tan = VariableElimination(model_tan)\n",
        "query_tan = inference_tan.query(variables=['Loan Status'], evidence=test_data.to_dict('records')[0], joint=False)\n",
        "print('Tan Algorithm:', query_tan['Loan Status'])\n",
        "\n",
        "# Predict the loan status for the test data using the Variable Elimination method for the Markov algorithm\n",
        "inference_markov = VariableElimination(model_markov)\n",
        "query_markov = inference_markov.query(variables=['Loan Status'], evidence=test_data.to_dict('records')[0], joint=False)\n",
        "print('Markov Algorithm:', query_markov['Loan Status'])\n",
        "\n",
        "# Predict the loan status for the test data using the Variable Elimination method for the Markov with feature selection algorithm\n",
        "inference_markov_fs = VariableElimination(model_markov_fs)\n",
        "query_markov_fs = inference_markov_fs.query(variables=['Loan Status'], evidence=test_data.to_dict('records')[0], joint=False)\n",
        "print('Markov with Feature Selection Algorithm:', query_markov_fs['Loan Status'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bayesian Model with smaller sample dataset\n",
        "### Taken from the SPSS Modeler with sample node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample instances from the dataset are given below\n",
            "         ID  Loan Amount  Funded Amount  Funded Amount Investor  Term   \n",
            "0  65087372        10000          32236            12329.362860    59  \\\n",
            "1  41969824        34653          18985             4917.125714    58   \n",
            "2  16437877        10997           7637            13290.569560    58   \n",
            "3   4359149        17583          31569             8380.168440    58   \n",
            "4  29423305        11410          25249            12361.413910    36   \n",
            "\n",
            "   Interest Rate Grade Sub Grade Home Type   Home Amount  ...   \n",
            "0      11.135007     B        C4  MORTGAGE  176346.62670  ...  \\\n",
            "1      10.590153     F        B1  MORTGAGE   60883.55633  ...   \n",
            "2      14.649411     D        D2       OWN   65773.90572  ...   \n",
            "3       8.999372     B        D1  MORTGAGE  187490.51610  ...   \n",
            "4      13.415264     C        A1  MORTGAGE   82789.56019  ...   \n",
            "\n",
            "  Total Collection Amount  Total Current Balance   \n",
            "0                      31                 311301  \\\n",
            "1                    1572                 304173   \n",
            "2                      26                  97114   \n",
            "3                      41                  71887   \n",
            "4                      45                 407132   \n",
            "\n",
            "   Total Revolving Credit Limit  Loan Status  Grade_Reclassify   \n",
            "0                          6619            0                 2  \\\n",
            "1                         28826            0                 6   \n",
            "2                         40565            0                 4   \n",
            "3                          4141            0                 2   \n",
            "4                          6305            0                 3   \n",
            "\n",
            "   Sub-Grade_Reclassify  Home-Type_Reclassify  Verification-Status_Reclassify   \n",
            "0                    14                     1                               1  \\\n",
            "1                     6                     1                               2   \n",
            "2                    17                     2                               3   \n",
            "3                    16                     1                               3   \n",
            "4                     1                     1                               1   \n",
            "\n",
            "   Initial-List-Status_Reclassify App-Type_Reclassify  \n",
            "0                               1                   0  \n",
            "1                               1                   0  \n",
            "2                               1                   0  \n",
            "3                               1                   0  \n",
            "4                               0                   0  \n",
            "\n",
            "[5 rows x 37 columns]\n",
            "\n",
            " Attributes and datatypes\n",
            "ID                                  int64\n",
            "Loan Amount                         int64\n",
            "Funded Amount                       int64\n",
            "Funded Amount Investor            float64\n",
            "Term                                int64\n",
            "Interest Rate                     float64\n",
            "Grade                              object\n",
            "Sub Grade                          object\n",
            "Home Type                          object\n",
            "Home Amount                       float64\n",
            "Verification Status                object\n",
            "Debit to Income                   float64\n",
            "Delinquency - two years             int64\n",
            "Inquires - six months               int64\n",
            "Open Account                        int64\n",
            "Public Record                       int64\n",
            "Revolving Balance                   int64\n",
            "Revolving Utilities               float64\n",
            "Total Accounts                      int64\n",
            "Initial List Status                object\n",
            "Total Received Interest           float64\n",
            "Total Received Late Fee           float64\n",
            "Recoveries                        float64\n",
            "Collection Recovery Fee           float64\n",
            "Collection 12 months Medical        int64\n",
            "Application Type                   object\n",
            "Last week Pay                       int64\n",
            "Total Collection Amount             int64\n",
            "Total Current Balance               int64\n",
            "Total Revolving Credit Limit        int64\n",
            "Loan Status                         int64\n",
            "Grade_Reclassify                    int64\n",
            "Sub-Grade_Reclassify                int64\n",
            "Home-Type_Reclassify                int64\n",
            "Verification-Status_Reclassify      int64\n",
            "Initial-List-Status_Reclassify      int64\n",
            "App-Type_Reclassify                 int64\n",
            "dtype: object\n",
            "\n",
            "Learning CPD using Maximum likelihood estimators\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pgmpy/models/BayesianModel.py:8: FutureWarning: BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 414. TiB for an array with shape (227862581760000,) and data type int16",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m model\u001b[39m=\u001b[39m BayesianModel([(\u001b[39m'\u001b[39m\u001b[39mLoan Amount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLoan Status\u001b[39m\u001b[39m'\u001b[39m), (\u001b[39m'\u001b[39m\u001b[39mTerm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLoan Status\u001b[39m\u001b[39m'\u001b[39m), (\u001b[39m'\u001b[39m\u001b[39mInterest Rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLoan Status\u001b[39m\u001b[39m'\u001b[39m), (\u001b[39m'\u001b[39m\u001b[39mHome Amount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLoan Status\u001b[39m\u001b[39m'\u001b[39m), (\u001b[39m'\u001b[39m\u001b[39mDebit to Income\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLoan Status\u001b[39m\u001b[39m'\u001b[39m), (\u001b[39m'\u001b[39m\u001b[39mDelinquency - two years\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLoan Status\u001b[39m\u001b[39m'\u001b[39m), (\u001b[39m'\u001b[39m\u001b[39mTotal Accounts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLoan Status\u001b[39m\u001b[39m'\u001b[39m)])\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mLearning CPD using Maximum likelihood estimators\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m model\u001b[39m.\u001b[39;49mfit(heartDisease,estimator\u001b[39m=\u001b[39;49mMaximumLikelihoodEstimator)\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Inferencing with Bayesian Network:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m HeartDiseasetest_infer \u001b[39m=\u001b[39m VariableElimination(model)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pgmpy/models/BayesianNetwork.py:586\u001b[0m, in \u001b[0;36mBayesianNetwork.fit\u001b[0;34m(self, data, estimator, state_names, complete_samples_only, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEstimator object should be a valid pgmpy estimator.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    580\u001b[0m _estimator \u001b[39m=\u001b[39m estimator(\n\u001b[1;32m    581\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    582\u001b[0m     data,\n\u001b[1;32m    583\u001b[0m     state_names\u001b[39m=\u001b[39mstate_names,\n\u001b[1;32m    584\u001b[0m     complete_samples_only\u001b[39m=\u001b[39mcomplete_samples_only,\n\u001b[1;32m    585\u001b[0m )\n\u001b[0;32m--> 586\u001b[0m cpds_list \u001b[39m=\u001b[39m _estimator\u001b[39m.\u001b[39;49mget_parameters(n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    587\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_cpds(\u001b[39m*\u001b[39mcpds_list)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pgmpy/estimators/MLE.py:96\u001b[0m, in \u001b[0;36mMaximumLikelihoodEstimator.get_parameters\u001b[0;34m(self, n_jobs, weighted)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_parameters\u001b[39m(\u001b[39mself\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, weighted\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m    Method to estimate the model parameters (CPDs) using Maximum Likelihood\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m    Estimation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m    <TabularCPD representing P(D:2 | C:2) at 0x7f7b4df822b0>]\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     parameters \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\n\u001b[1;32m     97\u001b[0m         delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimate_cpd)(node, weighted) \u001b[39mfor\u001b[39;49;00m node \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mnodes()\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m parameters\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m job, i, func, args, kwds \u001b[39m=\u001b[39m task\n\u001b[1;32m    124\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     result \u001b[39m=\u001b[39m (\u001b[39mTrue\u001b[39;00m, func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    126\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[39mif\u001b[39;00m wrap_exception \u001b[39mand\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _helper_reraises_exception:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py:620\u001b[0m, in \u001b[0;36mSafeFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    619\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    621\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    622\u001b[0m         \u001b[39m# We capture the KeyboardInterrupt and reraise it as\u001b[39;00m\n\u001b[1;32m    623\u001b[0m         \u001b[39m# something different, as multiprocessing does not\u001b[39;00m\n\u001b[1;32m    624\u001b[0m         \u001b[39m# interrupt processing for a KeyboardInterrupt\u001b[39;00m\n\u001b[1;32m    625\u001b[0m         \u001b[39mraise\u001b[39;00m WorkerInterrupt() \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pgmpy/estimators/MLE.py:148\u001b[0m, in \u001b[0;36mMaximumLikelihoodEstimator.estimate_cpd\u001b[0;34m(self, node, weighted)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mestimate_cpd\u001b[39m(\u001b[39mself\u001b[39m, node, weighted\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    103\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m    Method to estimate the CPD for a given variable.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m    ╘══════╧══════╧══════╧══════╧══════╛\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     state_counts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate_counts(node, weighted\u001b[39m=\u001b[39;49mweighted)\n\u001b[1;32m    150\u001b[0m     \u001b[39m# if a column contains only `0`s (no states observed for some configuration\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[39m# of parents' states) fill that column uniformly instead\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     state_counts\u001b[39m.\u001b[39mvalues[:, (state_counts\u001b[39m.\u001b[39mvalues \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mall(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pgmpy/estimators/base.py:274\u001b[0m, in \u001b[0;36mParameterEstimator.state_counts\u001b[0;34m(self, variable, weighted, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39mReturn counts how often each state of 'variable' occurred in the data.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39mIf the variable has parents, counting is done conditionally\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39mc2  0   0   1   0\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m parents \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mget_parents(variable))\n\u001b[0;32m--> 274\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(ParameterEstimator, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mstate_counts(\n\u001b[1;32m    275\u001b[0m     variable, parents\u001b[39m=\u001b[39;49mparents, weighted\u001b[39m=\u001b[39;49mweighted, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    276\u001b[0m )\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pgmpy/estimators/base.py:184\u001b[0m, in \u001b[0;36mBaseEstimator.state_counts\u001b[0;34m(self, variable, parents, complete_samples_only, weighted, reindex)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mif\u001b[39;00m reindex:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# reindex rows & columns to sort them and to add missing ones\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[39m# missing row    = some state of 'variable' did not occur in data\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39m# missing column = some state configuration of current 'variable's parents\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39m#                  did not occur in data\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     row_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_names[variable]\n\u001b[0;32m--> 184\u001b[0m     column_index \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mMultiIndex\u001b[39m.\u001b[39;49mfrom_product(parents_states, names\u001b[39m=\u001b[39;49mparents)\n\u001b[1;32m    185\u001b[0m     state_counts \u001b[39m=\u001b[39m state_count_data\u001b[39m.\u001b[39mreindex(\n\u001b[1;32m    186\u001b[0m         index\u001b[39m=\u001b[39mrow_index, columns\u001b[39m=\u001b[39mcolumn_index\n\u001b[1;32m    187\u001b[0m     )\u001b[39m.\u001b[39mfillna(\u001b[39m0\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/multi.py:656\u001b[0m, in \u001b[0;36mMultiIndex.from_product\u001b[0;34m(cls, iterables, sortorder, names)\u001b[0m\n\u001b[1;32m    653\u001b[0m     names \u001b[39m=\u001b[39m [\u001b[39mgetattr\u001b[39m(it, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m    655\u001b[0m \u001b[39m# codes are all ndarrays, so cartesian_product is lossless\u001b[39;00m\n\u001b[0;32m--> 656\u001b[0m codes \u001b[39m=\u001b[39m cartesian_product(codes)\n\u001b[1;32m    657\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(levels, codes, sortorder\u001b[39m=\u001b[39msortorder, names\u001b[39m=\u001b[39mnames)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/reshape/util.py:60\u001b[0m, in \u001b[0;36mcartesian_product\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m     b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(cumprodX)\n\u001b[1;32m     58\u001b[0m \u001b[39m# error: Argument of type \"int_\" cannot be assigned to parameter \"num\" of\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# type \"int\" in function \"tile_compat\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m     61\u001b[0m     tile_compat(\n\u001b[1;32m     62\u001b[0m         np\u001b[39m.\u001b[39;49mrepeat(x, b[i]),\n\u001b[1;32m     63\u001b[0m         np\u001b[39m.\u001b[39;49mprod(a[i]),  \u001b[39m# pyright: ignore[reportGeneralTypeIssues]\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, x \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(X)\n\u001b[1;32m     66\u001b[0m ]\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/reshape/util.py:62\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m     b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(cumprodX)\n\u001b[1;32m     58\u001b[0m \u001b[39m# error: Argument of type \"int_\" cannot be assigned to parameter \"num\" of\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# type \"int\" in function \"tile_compat\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m     61\u001b[0m     tile_compat(\n\u001b[0;32m---> 62\u001b[0m         np\u001b[39m.\u001b[39;49mrepeat(x, b[i]),\n\u001b[1;32m     63\u001b[0m         np\u001b[39m.\u001b[39mprod(a[i]),  \u001b[39m# pyright: ignore[reportGeneralTypeIssues]\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m     \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(X)\n\u001b[1;32m     66\u001b[0m ]\n",
            "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mrepeat\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:479\u001b[0m, in \u001b[0;36mrepeat\u001b[0;34m(a, repeats, axis)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_repeat_dispatcher)\n\u001b[1;32m    437\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrepeat\u001b[39m(a, repeats, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    438\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[39m    Repeat elements of an array.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m \n\u001b[1;32m    478\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mrepeat\u001b[39;49m\u001b[39m'\u001b[39;49m, repeats, axis\u001b[39m=\u001b[39;49maxis)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
            "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 414. TiB for an array with shape (227862581760000,) and data type int16"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv \n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "heartDisease = pd.read_csv('/Users/hittanshubhanderi/Downloads/outputpy.csv')\n",
        "heartDisease = heartDisease.replace('?',np.nan)\n",
        "\n",
        "print('Sample instances from the dataset are given below')\n",
        "print(heartDisease.head())\n",
        "\n",
        "print('\\n Attributes and datatypes')\n",
        "print(heartDisease.dtypes)\n",
        "\n",
        "model= BayesianModel([('Loan Amount', 'Loan Status'), ('Term', 'Loan Status'), ('Interest Rate', 'Loan Status'), ('Home Amount', 'Loan Status'), ('Debit to Income', 'Loan Status'), ('Delinquency - two years', 'Loan Status'), ('Total Accounts', 'Loan Status')])\n",
        "print('\\nLearning CPD using Maximum likelihood estimators')\n",
        "model.fit(heartDisease,estimator=MaximumLikelihoodEstimator)\n",
        "\n",
        "print('\\n Inferencing with Bayesian Network:')\n",
        "HeartDiseasetest_infer = VariableElimination(model)\n",
        "\n",
        "print('\\n 1. Probability of HeartDisease given evidence= restecg')\n",
        "q1=HeartDiseasetest_infer.query(variables=['Loan Status'],evidence={'Term':1})\n",
        "print(q1)\n",
        "\n",
        "print('\\n 2. Probability of HeartDisease given evidence= cp')\n",
        "q2=HeartDiseasetest_infer.query(variables=['Loan Status'],evidence={'Home Ownership':2})\n",
        "print(q2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bayesian Model with public runned model dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample instances from the dataset are given below\n",
            "   age  gender  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak   \n",
            "0   63       1   1       145   233    1        2      150      0      2.3  \\\n",
            "1   67       1   4       160   286    0        2      108      1      1.5   \n",
            "2   67       1   4       120   229    0        2      129      1      2.6   \n",
            "3   37       1   3       130   250    0        0      187      0      3.5   \n",
            "4   41       0   2       130   204    0        2      172      0      1.4   \n",
            "\n",
            "   slope ca thal  heartdisease  \n",
            "0      3  0    6             0  \n",
            "1      2  3    3             2  \n",
            "2      2  2    7             1  \n",
            "3      3  0    3             0  \n",
            "4      1  0    3             0  \n",
            "\n",
            " Attributes and datatypes\n",
            "age               int64\n",
            "gender            int64\n",
            "cp                int64\n",
            "trestbps          int64\n",
            "chol              int64\n",
            "fbs               int64\n",
            "restecg           int64\n",
            "thalach           int64\n",
            "exang             int64\n",
            "oldpeak         float64\n",
            "slope             int64\n",
            "ca               object\n",
            "thal             object\n",
            "heartdisease      int64\n",
            "dtype: object\n",
            "\n",
            "Learning CPD using Maximum likelihood estimators\n",
            "\n",
            " Inferencing with Bayesian Network:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pgmpy/models/BayesianModel.py:8: FutureWarning: BayesianModel has been renamed to BayesianNetwork. Please use BayesianNetwork class, BayesianModel will be removed in future.\n",
            "  warnings.warn(\n",
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pgmpy/factors/discrete/CPD.py:331: RuntimeWarning: invalid value encountered in divide\n",
            "  tabular_cpd.values = (cpd / cpd.sum(axis=0)).reshape(tabular_cpd.cardinality)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Sum or integral of conditional probabilities for node heartdisease is not equal to 1.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m model\u001b[39m.\u001b[39mfit(heartDisease,estimator\u001b[39m=\u001b[39mMaximumLikelihoodEstimator)\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Inferencing with Bayesian Network:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m HeartDiseasetest_infer \u001b[39m=\u001b[39m VariableElimination(model)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m 1. Probability of HeartDisease given evidence= restecg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m q1\u001b[39m=\u001b[39mHeartDiseasetest_infer\u001b[39m.\u001b[39mquery(variables\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mheartdisease\u001b[39m\u001b[39m'\u001b[39m],evidence\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mrestecg\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m1\u001b[39m})\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pgmpy/inference/base.py:67\u001b[0m, in \u001b[0;36mInference.__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model):\n\u001b[1;32m     66\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m---> 67\u001b[0m     model\u001b[39m.\u001b[39;49mcheck_model()\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, JunctionTree):\n\u001b[1;32m     70\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(chain(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mnodes()))\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pgmpy/models/BayesianNetwork.py:423\u001b[0m, in \u001b[0;36mBayesianNetwork.check_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39m# Check if the values of the CPD sum to 1.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cpd\u001b[39m.\u001b[39mis_valid_cpd():\n\u001b[0;32m--> 423\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    424\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSum or integral of conditional probabilities for node \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m}\u001b[39;00m\u001b[39m is not equal to 1.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(cpd\u001b[39m.\u001b[39mvariables) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(cpd\u001b[39m.\u001b[39mstate_names\u001b[39m.\u001b[39mkeys())) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    428\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    429\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCPD for \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have state names defined for all the variables.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Sum or integral of conditional probabilities for node heartdisease is not equal to 1."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv \n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "heartDisease = pd.read_csv('/Users/hittanshubhanderi/Downloads/7-dataset.csv')\n",
        "heartDisease = heartDisease.replace('?',np.nan)\n",
        "\n",
        "print('Sample instances from the dataset are given below')\n",
        "print(heartDisease.head())\n",
        "\n",
        "print('\\n Attributes and datatypes')\n",
        "print(heartDisease.dtypes)\n",
        "\n",
        "model= BayesianModel([('age','heartdisease'),('gender','heartdisease'),('exang','heartdisease'),('cp','heartdisease'),('heartdisease','restecg'),('heartdisease','chol')])\n",
        "print('\\nLearning CPD using Maximum likelihood estimators')\n",
        "model.fit(heartDisease,estimator=MaximumLikelihoodEstimator)\n",
        "\n",
        "print('\\n Inferencing with Bayesian Network:')\n",
        "HeartDiseasetest_infer = VariableElimination(model)\n",
        "\n",
        "print('\\n 1. Probability of HeartDisease given evidence= restecg')\n",
        "q1=HeartDiseasetest_infer.query(variables=['heartdisease'],evidence={'restecg':1})\n",
        "print(q1)\n",
        "\n",
        "print('\\n 2. Probability of HeartDisease given evidence= cp ')\n",
        "q2=HeartDiseasetest_infer.query(variables=['heartdisease'],evidence={'cp':2})\n",
        "print(q2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
